{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf45364f-bbf7-458c-9c35-e475c102484c",
   "metadata": {},
   "source": [
    "# Example Notebook to show how to use RAPIDS+Pytorch with Triton\n",
    "\n",
    "This notebook calls a ensemble model which uses RAPIDS+Pytorch with Triton\n",
    "\n",
    "\n",
    "<img src=\"notebook_images/ensemble_rapids_simple.jpg\" width=\"300\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ca165-da53-4319-823a-8bb670386ca0",
   "metadata": {},
   "source": [
    "### Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60080a0e-9c82-4290-b4cd-21fc66599817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nvidia-pyindex\n",
    "# !pip install tritonclient[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13897c7a-e6e6-4220-97e3-647f40d51488",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67753be1-6a95-4744-8987-f3d66b997dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import grpc\n",
    "from tritonclient.grpc import service_pb2\n",
    "from tritonclient.grpc import service_pb2_grpc\n",
    "import tritonclient.grpc as grpcclient\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ee0ed-1ad1-4bfb-86ee-8b9c4787132c",
   "metadata": {},
   "source": [
    "###  Connect to the Triton End to End Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800b69f8-4e40-42f4-a5b0-3ab1df020f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='localhost:8001'\n",
    "\n",
    "triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "\n",
    "channel = grpc.insecure_channel(url)\n",
    "grpc_stub = service_pb2_grpc.GRPCInferenceServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9435c10-adef-4d23-a225-35905d0abafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model metadata:\n",
      "name: \"huggingface_tokenizer\"\n",
      "versions: \"1\"\n",
      "platform: \"python\"\n",
      "inputs {\n",
      "  name: \"product_reviews\"\n",
      "  datatype: \"BYTES\"\n",
      "  shape: -1\n",
      "}\n",
      "outputs {\n",
      "  name: \"input_ids\"\n",
      "  datatype: \"INT32\"\n",
      "  shape: -1\n",
      "  shape: 256\n",
      "}\n",
      "outputs {\n",
      "  name: \"attention_mask\"\n",
      "  datatype: \"INT32\"\n",
      "  shape: -1\n",
      "  shape: 256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preprocessing_model = 'end_to_end_onnx'\n",
    "preprocessing_model = 'huggingface_tokenizer'\n",
    "request = service_pb2.ModelMetadataRequest(name=preprocessing_model,\n",
    "                                           version='1')\n",
    "response = grpc_stub.ModelMetadata(request)\n",
    "print(\"model metadata:\\n{}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328c4d8-df21-49d7-b64a-21919fc1fc83",
   "metadata": {},
   "source": [
    "## Send Request to Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a429b4-edc9-4518-9dd5-03df58956c65",
   "metadata": {},
   "source": [
    "### Prepare Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f88224e-5b55-4f23-8036-ff36ef97d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ls = ['The product is great', 'This product is bad','This product is good', 'This product is really bad']*1\n",
    "log_ls = [l.encode('utf-8') for l in log_ls]\n",
    "log_ar = np.array(log_ls).reshape(1,len(log_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448f01c-39db-4e05-8cba-d1685ef29dd8",
   "metadata": {},
   "source": [
    "### Request Sending Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f482b67e-8ae8-4f46-9131-36b4696ee74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_preprocess_request(log_ar, model_name='rapids_tokenizer'):\n",
    "    triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "    input_grpc = grpcclient.InferInput(\"product_reviews\",log_ar.shape,\"BYTES\")\n",
    "    input_grpc.set_data_from_numpy(log_ar)\n",
    "\n",
    "    outputs = []\n",
    "    outputs.append(grpcclient.InferRequestedOutput('input_ids'))\n",
    "    outputs.append(grpcclient.InferRequestedOutput('attention_mask'))\n",
    "\n",
    "    \n",
    "    output = triton_client.infer(model_name=model_name,\n",
    "                               inputs=[input_grpc],\n",
    "                              outputs=outputs)\n",
    "    \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4bf6c8-722c-4e04-b166-b9c31a7186ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74 ms ± 239 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output = send_preprocess_request(log_ar.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ad33b0-a115-48c6-a042-c626ac8d4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_inference_request(log_ar, model_name='end_to_end_pytorch'):\n",
    "    triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "    input_grpc = grpcclient.InferInput(\"product_reviews\",log_ar.shape,\"BYTES\")\n",
    "    input_grpc.set_data_from_numpy(log_ar)\n",
    "    outputs = []\n",
    "    outputs.append(grpcclient.InferRequestedOutput('preds'))\n",
    "    \n",
    "    output = triton_client.infer(model_name=model_name,\n",
    "                               inputs=[input_grpc],\n",
    "                              outputs=outputs)\n",
    "    \n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0648eed6-9a3b-4f2c-a876-c13c6769badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3 ms ± 63.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output = send_inference_request(log_ar,'end_to_end_onnx')\n",
    "#output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9c6a8c-877e-4ad0-9aa4-b3fe69a7bfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.5 ms ± 296 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output = send_inference_request(log_ar,'end_to_end_pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d681d-8d82-4dcf-9242-ca2def348a38",
   "metadata": {},
   "source": [
    "##  Predictions\n",
    "\n",
    "##### 1 is positive, 0 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7492f1c7-d02b-46e4-82fe-6c26c4fbd9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = send_inference_request(log_ar,'end_to_end_pytorch')\n",
    "output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b2a359-4c69-4082-8a17-33aef250aa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = send_inference_request(log_ar,'end_to_end_onnx')\n",
    "output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3895b2",
   "metadata": {},
   "source": [
    "# **added by tugrulkonuk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf95744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e53341",
   "metadata": {},
   "source": [
    "### Huggingface tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertTokenizer\n",
    "#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333834db",
   "metadata": {},
   "source": [
    "##### Random inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d149001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_length = 256\n",
    "input0 = grpcclient.InferInput('input_ids', (batch_size, seq_length), 'INT32')\n",
    "\n",
    "input1 = grpcclient.InferInput('attention_mask', (batch_size, seq_length), 'INT32')\n",
    "input1.set_data_from_numpy(np.ones((batch_size, seq_length), dtype=np.int32))\n",
    "\n",
    "output = grpcclient.InferRequestedOutput('preds')\n",
    "\n",
    "def run_random_inference(model_name='sentiment_model_pytorch'):\n",
    "    triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "    input0.set_data_from_numpy(np.random.randint(10000, size=(batch_size, seq_length), dtype=np.int32))\n",
    "    return triton_client.infer(model_name=model_name, inputs=[input0, input1], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b22ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = run_random_inference()\n",
    "output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29598a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an inference with a defined Huggingface tokenizer\n",
    "def run_inference(input_ls, tokenizer=BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=False),  model_name='sentiment_model_pytorch'):\n",
    "    triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "\n",
    "    output_t = tokenizer(input_ls, truncation=True, max_length=seq_length, padding='max_length')\n",
    "    output_d = {k:v for k,v in output_t.items()}\n",
    "    \n",
    "    input0 = grpcclient.InferInput('input_ids', (len(input_ls), seq_length), 'INT32')\n",
    "    input1 = grpcclient.InferInput('attention_mask', (len(input_ls), seq_length), 'INT32')\n",
    "\n",
    "    input0.set_data_from_numpy(np.array(output_d[\"input_ids\"]).astype(np.int32))\n",
    "    input1.set_data_from_numpy(np.array(output_d[\"attention_mask\"]).astype(np.int32))\n",
    "    \n",
    "    output = grpcclient.InferRequestedOutput('preds')\n",
    "    \n",
    "    return output_d, triton_client.infer(model_name=model_name, inputs=[input0, input1], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cda39bfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertTokenizerFast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14593/1825321294.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#log_ls = ['The product is great', 'This product is bad','This product is good', 'This product is really bad']*1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Carol is nice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'This product is bad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'This product is good'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'This product is really bad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertTokenizerFast' is not defined"
     ]
    }
   ],
   "source": [
    "log_ls = ['The product is great', 'This product is bad','This product is good', 'This product is really bad']*1\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "tokens, output = run_inference(log_ls, tokenizer)\n",
    "output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e41e7",
   "metadata": {},
   "source": [
    "##  Predictions\n",
    "\n",
    "##### 1 is positive, 0 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e3c3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "log_ls = ['The product is great', 'This product is bad','This product is good', 'This product is really bad']*1\n",
    "\n",
    "def send_inference_request_hugf(txt_ls, model_name='end_to_end_pytorch_hugf'):\n",
    "    triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "    input_grpc = grpcclient.InferInput(\"product_reviews\", shape=(1,len(txt_ls)), datatype=\"BYTES\")\n",
    "    input_grpc.set_data_from_numpy(np.asarray([txt_ls], dtype=object))\n",
    "    \n",
    "    \n",
    "    outputs = []\n",
    "    outputs.append(grpcclient.InferRequestedOutput('preds'))\n",
    "    \n",
    "    output = triton_client.infer(model_name=model_name,\n",
    "                               inputs=[input_grpc],\n",
    "                              outputs=outputs)\n",
    "    \n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbb9281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 256\n",
    "output = send_inference_request_hugf(log_ls)\n",
    "output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e268c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(log_ls[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971fb165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
