{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf45364f-bbf7-458c-9c35-e475c102484c",
   "metadata": {},
   "source": [
    "# Example Notebook to show how to use RAPIDS+Pytorch with Triton\n",
    "\n",
    "This notebook calls a ensemble model which uses RAPIDS+Pytorch with Triton\n",
    "\n",
    "\n",
    "<img src=\"notebook_images/ensemble_rapids_simple.jpg\" width=\"300\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ca165-da53-4319-823a-8bb670386ca0",
   "metadata": {},
   "source": [
    "### Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60080a0e-9c82-4290-b4cd-21fc66599817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nvidia-pyindex\n",
    "# !pip install tritonclient[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13897c7a-e6e6-4220-97e3-647f40d51488",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67753be1-6a95-4744-8987-f3d66b997dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import grpc\n",
    "from tritonclient.grpc import service_pb2\n",
    "from tritonclient.grpc import service_pb2_grpc\n",
    "import tritonclient.grpc as grpcclient\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ee0ed-1ad1-4bfb-86ee-8b9c4787132c",
   "metadata": {},
   "source": [
    "###  Connect to the Triton End to End Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b69f8-4e40-42f4-a5b0-3ab1df020f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='localhost:8001'\n",
    "\n",
    "triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "\n",
    "channel = grpc.insecure_channel(url)\n",
    "grpc_stub = service_pb2_grpc.GRPCInferenceServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9435c10-adef-4d23-a225-35905d0abafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_model = 'end_to_end_onnx'\n",
    "request = service_pb2.ModelMetadataRequest(name=preprocessing_model,\n",
    "                                           version='1')\n",
    "response = grpc_stub.ModelMetadata(request)\n",
    "print(\"model metadata:\\n{}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328c4d8-df21-49d7-b64a-21919fc1fc83",
   "metadata": {},
   "source": [
    "## Send Request to Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a429b4-edc9-4518-9dd5-03df58956c65",
   "metadata": {},
   "source": [
    "### Prepare Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88224e-5b55-4f23-8036-ff36ef97d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ls = ['The product is great', 'This product is bad','This product is good', 'This product is really bad']*1\n",
    "log_ls = [l.encode('utf-8') for l in log_ls]\n",
    "log_ar = np.array(log_ls).reshape(1,len(log_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448f01c-39db-4e05-8cba-d1685ef29dd8",
   "metadata": {},
   "source": [
    "### Request Sending Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482b67e-8ae8-4f46-9131-36b4696ee74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_preprocess_request(log_ar, model_name='rapids_tokenizer'):\n",
    "    triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "    input_grpc = grpcclient.InferInput(\"product_reviews\",log_ar.shape,\"BYTES\")\n",
    "    input_grpc.set_data_from_numpy(log_ar)\n",
    "\n",
    "    outputs = []\n",
    "    outputs.append(grpcclient.InferRequestedOutput('input_ids'))\n",
    "    outputs.append(grpcclient.InferRequestedOutput('attention_mask'))\n",
    "\n",
    "    \n",
    "    output = triton_client.infer(model_name=model_name,\n",
    "                               inputs=[input_grpc],\n",
    "                              outputs=outputs)\n",
    "    \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bf6c8-722c-4e04-b166-b9c31a7186ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "output = send_preprocess_request(log_ar.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad33b0-a115-48c6-a042-c626ac8d4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_inference_requet(log_ar, model_name='end_to_end_pytorch'):\n",
    "    triton_client = grpcclient.InferenceServerClient(url=url,verbose=False)\n",
    "    input_grpc = grpcclient.InferInput(\"product_reviews\",log_ar.shape,\"BYTES\")\n",
    "    input_grpc.set_data_from_numpy(log_ar)\n",
    "    outputs = []\n",
    "    outputs.append(grpcclient.InferRequestedOutput('preds'))\n",
    "    \n",
    "    output = triton_client.infer(model_name=model_name,\n",
    "                               inputs=[input_grpc],\n",
    "                              outputs=outputs)\n",
    "    \n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648eed6-9a3b-4f2c-a876-c13c6769badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "output = send_inference_requet(log_ar,'end_to_end_onnx')\n",
    "#output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c6a8c-877e-4ad0-9aa4-b3fe69a7bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "output = send_inference_requet(log_ar,'end_to_end_pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d681d-8d82-4dcf-9242-ca2def348a38",
   "metadata": {},
   "source": [
    "##  Predictions\n",
    "\n",
    "##### 1 is positive, 0 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492f1c7-d02b-46e4-82fe-6c26c4fbd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = send_inference_requet(log_ar,'end_to_end_pytorch')\n",
    "output.as_numpy('preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2a359-4c69-4082-8a17-33aef250aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = send_inference_requet(log_ar,'end_to_end_onnx')\n",
    "output.as_numpy('preds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
